---
layout: doc
title: Npgsql 4.0 Release Notes
---

# Npgsql 4.0 (preview1)

> [!Warning]
> These release notes are for a prerelease version of Npgsql. It is being released to gather community feedback and assess stability, and should not be used in a critical production environment.

The first preview of Npgsql 4.0 is out and available at nuget.org.

Special thanks goes out to @YohDeadfall, @Brar and @rwasef1830 for their contributions.

## High performance

A concentrated effort has substantially increased Npgsql performance, especially in highly concurrent, low-latency scenarios. Improvements include:

* Rewriting of the connection pool to be lock-free, since contention started to be an issue in highly concurrent, short-lived connection scenarios ([#1839](https://github.com/npgsql/npgsql/issues/1839)).
* New API for generically providing parameters, avoiding boxing of value type ([#1639](https://github.com/npgsql/npgsql/issues/1639)).
* Significant reduction of allocations through recycling and other techniques.
* Avoiding numerous internal async calls where they weren't needed.
* ... many others

Does the new Npgsql run faster for you? If so, let us know! Is it running slower?? Let us know even more urgently by opening an issue.

If you're interested in Npgsql performance and haven't yet seen [the performance page](../performance.md), it's a good opportunity to check it out (it's valid also for 3.2 users).

## Extensibility

Npgsql now provides an extensibility API for adding PostgreSQL type support and changing mappings, opening Npgsql up to new possibilities ([#1475](https://github.com/npgsql/npgsql/issues/1475)). Current plugins are:

* [Npgsql.Json.NET](../types/jsonnet.md): works with [Newtonsoft Json.NET](https://www.newtonsoft.com/json) to automatically serialize and deserialize PostgreSQL's `jsonb` and `json` types to your objects, providing a seamless database JSON programming experience.
* [Npgsql.Nodatime](../types/nodatime.md): makes Npgsql read and write [Nodatime](https://nodatime.org/) types instead of the standard built-in ones (e.g. `DateTime`). The Nodatime types are safer and address many issues in the built-in types, and are now the recommended way of doing date/time with Npgsql.
* Npgsql.NetTopologySuite (in progress): makes Npgsql map [PostGIS spatial types](https://postgis.net/) to [NetTopologySuite](https://github.com/NetTopologySuite/NetTopologySuite) instead of the internal types previously provided by Npgsql (these types are available via [Npgsql.LegacyPostgis](../types/legacy-postgis.md)). NetTopologySuite is a full-fledged .NET spatial library which makes much more sense for interacting with PostGIS, and also includes converters to other formats and libraries ([GeoJSON](http://geojson.org/), [Microsoft.Spatial](http://odata.github.io/odata.net/#03-01-define-spatial-property)). Thanks @YohDeadfall.
* [Npgsql.LegacyPostgis](../types/legacy-postgis.md): contains the previous PostGIS support (e.g. `PostgisPoint`), which has been moved out into its own plugin.
* In addition, a type loading extensibility point has been added to improve support for non-PostgreSQL databases which don't fully support the PostgreSQL system tables ([#1486](https://github.com/npgsql/npgsql/issues/1486)).

Please give us ideas for more plugins by opening an issue! If you plan to try to write one yourself, be aware that it's quite low-level (you need to handle PostgreSQL binary encoding of types), and that the API is likely to evolve and break.

## Others

* Better "reflection" capabilities. Continuing work from 3.2, Npgsql now exposes more information about PostgreSQL types, allowing you to dynamically reflect on columns types returned by queries, or required as parameters ([#1276](https://github.com/npgsql/npgsql/issues/1276), [#1779](https://github.com/npgsql/npgsql/issues/1779)).
* Derive parameters for queries. You can now also use `NpgsqlCommandBuilder` to dynamically understand which parameters and types are required for arbitrary queries (previously supported only for functions) ([#1698](https://github.com/npgsql/npgsql/pull/1698), thanks @Brar!).
* Npgsql better supports working with enums and composites, even without mapping them, and better supports new types introduced via plugins ([#1792](https://github.com/npgsql/npgsql/issues/1792)).
* Fix the binary COPY API to make it interact better with exceptions ([#1646](https://github.com/npgsql/npgsql/issues/1646)).

In addition to more documentation, several blog posts are planned to explain the above in more details (to be announced on [@shayrojansky](https://twitter.com/shayrojansky)).

## Breaking Changes from 3.2

> [!CAUTION]
> The API for binary import (COPY IN) has changed substantially in a breaking way, and code from 3.2 will *not* work as-is on 3.3.
>
> You must now call `NpgsqlBinaryImporter.Complete()` to save your imported data; not doing so will roll the operation back. `NpgsqlBinaryImporter.Cancel()` has been removed - simply closing/disposing the importer will implicitly cancel the import. This is similar to how `TransactionScope` works and is necessary to prevent accidental commit of data on exception. See [#1646](https://github.com/npgsql/npgsql/issues/1646).

* .NET Standard 1.3 is no longer supported. .NET Standard 2.0 is the lowest supported version.
* Npgsql used to use its own internal TLS/SSL due to issues with some server. As these issues have been resolved, the standard .NET SslStream is now used by default ([#1482](https://github.com/npgsql/npgsql/issues/1482)), but you can still set `Use SSL Stream=false` to keep using the internal implementation (please report why you need this, as it's likely the internal implementation will be removed in a future release).
* The reader instances returned by `NpgsqlCommand.ExecuteReader()` are now recycled, to reduce memory allocations ([#1649](https://github.com/npgsql/npgsql/issues/1649)). You should not keep a reference or interact with a reader after its command has been disposed (such interaction was limited in any case).
* The `Min Pool Size` parameter will no longer make the pool create new connections internally - it will only have an effect on how many connections are pruned. Previously, in various points the pool would check if the current number of connections was below `Min Pool Size`, and if so, automatically created new ones - this no longer happens.
* Parameter types have become more strict. Previous versions allowed to you pass arbitrary value types, such as writing CLR string to int columns, or anything that implemented IConvertible. Although some implicit conversions are still supported (e.g. long -> int, short -> int), some have been removed.
* Column names are no longer case-insensitive and must be specified exactly as retrieved from the database (e.g. `NpgsqlDataReader.GetOrdinal()`).
* `NpgsqlParameter.EnumType` and `NpgsqlParameter.SpecificType` have been removed. See [Composites and Enums](../types/enums_and_composites.md) for more details.
* Parameter names are no longer trimmed, set your names to the exact parameter name specified in your SQL.
* If a parameter's name isn't set, it will no longer default to Parameter1, Parameter2, etc.
* The following APIs "connection capability" APIs have been removed from NpgsqlConnection: `UseConformantStrings`, `SupportsEStringPrefix`, `UseSslStream`.
* The default name translator, `NpgsqlSnakeCaseNameTranslator`, has been changed to handle acronyms better. Given the property name `IsJSON`, the old translator algorithm would output `is_j_s_o_n`, while the new outputs `is_json`. To revert back to the old algorithm, create a `NpgsqlSnakeCaseNameTranslator` instance with `legacyMode: true` and pass it when calling the `MapComposite` and `MapEnum` methods.
* If you are reading tables as composites ([#990](https://github.com/npgsql/npgsql/issues/990)), you will have to add the new `Load Table Composites` to your connection string.
* `NpgsqlConnection.GetSchema()` will no longer return system tables (i.e. tables in schemas `pg_catalog` and `information_schema`), [#1831](https://github.com/npgsql/npgsql/issues/1831).
* You may no longer have multiple streams or text readers open on a reader (this was previously supported with non-sequential readers). Accessing a new column closes any open stream or text reader.
